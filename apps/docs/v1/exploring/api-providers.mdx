---
title: "Exploring API Providers"
description: "Learn about the platforms and services that host and distribute AI models through APIs."
---

**API providers** are the platforms that make AI models accessible via APIs ‚Äî offering developers and organisations a way to integrate cutting-edge models into their products without managing infrastructure or fine-tuning directly.

While **organisations** are responsible for creating and training models, **providers** focus on **hosting, routing, and delivering** those models efficiently and reliably.

---

## What is an API provider?

An API provider offers programmatic access to one or more AI models, often with additional functionality such as:

-   Authentication and usage management
-   Load balancing and request routing
-   Logging, analytics, and cost tracking
-   Unified APIs or SDKs for multiple models
-   Regional or data-compliant hosting

Examples of providers include:

-   **OpenAI API** ‚Äî for GPT and Whisper models.
-   **Anthropic API** ‚Äî for Claude models.
-   **Google Gemini API** ‚Äî for Gemini 1.5 and Imagen models.
-   **Mistral API** ‚Äî for Mistral Large and Mixtral models.
-   **AI Stats Gateway** ‚Äî for unified access across multiple providers.
-   **OpenRouter** ‚Äî for community-based multi-model routing.

---

## Provider vs Organisation

| Aspect           | Organisation                   | API Provider                                                  |
| ---------------- | ------------------------------ | ------------------------------------------------------------- |
| **Purpose**      | Develops and trains AI models. | Hosts and serves models via API.                              |
| **Example**      | _Anthropic_ builds Claude.     | _OpenRouter_ or _AI Stats Gateway_ provides access to Claude. |
| **Focus**        | Research and innovation.       | Reliability, access, and developer tools.                     |
| **Distribution** | Limited to their own models.   | May host models from many organisations.                      |

Many providers (like OpenAI or Google) are _both_ ‚Äî developing and hosting their own models.

---

## What‚Äôs inside a provider page

Each provider listed on AI Stats includes:

| Section              | Description                                                                             |
| -------------------- | --------------------------------------------------------------------------------------- |
| **Overview**         | Name, website, country, supported endpoints, and data centre locations.                 |
| **Available Models** | List of models hosted by the provider, including their latest versions.                 |
| **Pricing**          | Provider-specific pricing structure (per token, image, or request).                     |
| **Rate Limits**      | Information on daily or per-minute request limits.                                      |
| **Features**         | Supported capabilities like streaming, batch processing, fine-tuning, or custom models. |
| **Endpoints**        | Direct link to API documentation or health endpoints.                                   |
| **SDKs & Tools**     | Links to official or community SDKs, CLI tools, or integrations.                        |

---

## Example provider data

```json
{
	"id": "openai",
	"name": "OpenAI API",
	"country": "United States",
	"website": "https://platform.openai.com",
	"models_supported": ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo", "whisper-1"],
	"pricing": {
		"input_per_1k_tokens_usd": 0.005,
		"output_per_1k_tokens_usd": 0.015
	},
	"features": ["streaming", "json_mode", "function_calling", "fine_tuning"],
	"rate_limits": {
		"tier_1": "60 RPM, 60,000 TPM",
		"tier_2": "600 RPM, 600,000 TPM"
	}
}
```

---

## AI Stats Gateway

The **AI Stats Gateway** itself is also an API provider ‚Äî but with a twist.  
It acts as a **meta-provider**, offering a unified interface across multiple platforms.

### Benefits of the Gateway

-   üîÅ **Unified endpoints** ‚Äî single format across all supported providers.
-   ü™∂ **Smart routing** ‚Äî automatically selects the best available provider.
-   üß† **Provider-agnostic SDKs** ‚Äî consistent code, regardless of backend.
-   üìä **Integrated analytics** ‚Äî usage tracking and cost normalisation.
-   üîë **BYOK (Bring Your Own Key)** ‚Äî connect your own provider API keys.

You can learn more about the Gateway and how to integrate with it in the [Developers Introduction](/v1/developers/introduction).

---

## Understanding pricing and performance

Each provider‚Äôs pricing and performance can vary significantly.  
AI Stats makes this transparent by normalising data into **USD per 1,000 tokens (or equivalent)** and comparing latency metrics where available.

| Metric                             | Description                          |
| ---------------------------------- | ------------------------------------ |
| **Input Price (USD / 1K tokens)**  | Cost of tokens sent to the API.      |
| **Output Price (USD / 1K tokens)** | Cost of tokens generated by the API. |
| **Average Latency (ms)**           | Time from request to response.       |
| **Throughput (tokens/sec)**        | Processing speed of the API.         |
| **Availability (%)**               | Uptime and reliability score.        |

Explore aggregated metrics in the [Pricing & Performance](/v1/exploring/pricing-performance) section.

---

## Choosing a provider

When selecting a provider, consider the following:

-   ‚öôÔ∏è **Supported models** ‚Äî ensure the models you need are available.
-   üåç **Region & compliance** ‚Äî verify data residency and privacy compliance.
-   üí∞ **Pricing tiers** ‚Äî evaluate based on budget and usage volume.
-   üß© **Integration options** ‚Äî check for SDKs or tools in your language.
-   üìà **Performance** ‚Äî look for low latency and high uptime.
-   üîí **Security** ‚Äî confirm API key management and authentication methods.

AI Stats aggregates this information for all supported providers to help you make informed decisions.

---

## Example use cases

| Goal                                   | Example                                                     |
| -------------------------------------- | ----------------------------------------------------------- |
| Find all providers offering Claude 3.5 | ‚ÄúWhich APIs support Anthropic‚Äôs Claude 3.5?‚Äù                |
| Compare latency across providers       | ‚ÄúIs Mistral faster through OpenRouter or the native API?‚Äù   |
| Optimise pricing                       | ‚ÄúWhat‚Äôs the cheapest way to access GPT-4o for 100K tokens?‚Äù |
| Integrate multiple backends            | ‚ÄúHow can I route between providers dynamically?‚Äù            |

---

## Contributing provider data

You can help expand AI Stats by adding new providers or updating existing ones.

<Card
	title="Contribute Provider Data"
	icon="github"
	href="/v1/contributing/contributing-to-the-api"
	horizontal
>
	Learn how to add or update provider listings in the database.
</Card>

---

## Next steps

Now that you understand how providers work, continue to the **Pricing & Performance** page to see how models and providers compare side-by-side.

<Card
	title="Explore Pricing & Performance"
	icon="scale"
	href="/v1/exploring/pricing-performance"
	horizontal
>
	Compare costs, speeds, and efficiencies across models and providers.
</Card>
