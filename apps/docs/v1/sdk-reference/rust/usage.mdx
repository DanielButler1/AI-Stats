---
title: "Rust SDK Usage"
description: "Endpoint-by-endpoint examples using the Rust SDK."
---

## Setup

```rust
use ai_stats_sdk::apis::configuration::Configuration;

let mut config = Configuration::new();
config.bearer_access_token = Some("your-api-key".to_string());
```

## Chat completions

```rust
use ai_stats_sdk::apis::completions_api;
use ai_stats_sdk::models::{ChatCompletionsRequest, ChatMessage, MessageContent};

let mut request = ChatCompletionsRequest::new(
    "openai/gpt-4o-mini".to_string(),
    vec![
        ChatMessage::System(ai_stats_sdk::models::ChatMessageSystem::new(
            ai_stats_sdk::models::chat_message_system::Role::System,
            MessageContent::String("You are a helpful assistant.".to_string())
        )),
        ChatMessage::User(ai_stats_sdk::models::ChatMessageUser::new(
            ai_stats_sdk::models::chat_message_user::Role::User,
            MessageContent::String("What is AI Stats?".to_string())
        )),
    ]
);
request.temperature = Some(0.7);

let response = completions_api::create_chat_completion(&config, request).await?;
```

## Responses

```rust
use ai_stats_sdk::apis::responses_api;
use ai_stats_sdk::models::ResponsesRequest;

let mut request = ResponsesRequest::new("openai/gpt-4.1".to_string());
request.text = Some(serde_json::json!("Summarise this"));

let response = responses_api::create_response(&config, request).await?;
```

## Images

```rust
use ai_stats_sdk::apis::images_api;
use ai_stats_sdk::models::ImageGenerationRequest;

let request = ImageGenerationRequest::new(
    "openai/gpt-image-1".to_string(),
    "A lighthouse at golden hour".to_string()
);

let response = images_api::images_generations_post(&config, request).await?;
```

## Audio

```rust
use ai_stats_sdk::apis::audio_api;
use ai_stats_sdk::models::AudioSpeechRequest;

let request = AudioSpeechRequest::new(
    "openai/gpt-4o-mini-tts".to_string(),
    "Hello world".to_string()
);

let response = audio_api::audio_speech_post(&config, request).await?;
```

## Video

```rust
use ai_stats_sdk::apis::video_api;
use ai_stats_sdk::models::VideoGenerationRequest;

let request = VideoGenerationRequest::new(
    "openai/gpt-video-1".to_string(),
    "A serene mountain lake at sunrise".to_string()
);

let response = video_api::video_generation_post(&config, request).await?;
```

## Embeddings

```rust
use ai_stats_sdk::apis::configuration::Configuration;
use serde_json::json;

let request_body = json!({
    "model": "openai/text-embedding-3-large",
    "input": "Sample text"
});

let response = config.client
    .post(&format!("{}/embeddings", config.base_path))
    .bearer_auth(config.bearer_access_token.as_ref().unwrap())
    .json(&request_body)
    .send()
    .await?;
```

## Moderations

```rust
use ai_stats_sdk::apis::moderations_api;
use ai_stats_sdk::models::{ModerationRequest, ModerationRequestInput};

let request = ModerationRequest::new(
    "openai/omni-moderation-latest".to_string(),
    ModerationRequestInput::String("Some text to check".to_string())
);

let response = moderations_api::moderations_post(&config, request).await?;
```

## Batch & files

```rust
use ai_stats_sdk::apis::{batch_api, files_api};
use ai_stats_sdk::models::BatchRequest;
use std::path::PathBuf;

let file_path = PathBuf::from("path/to/file.jsonl");
let uploaded_file = files_api::files_post(&config, Some("batch"), Some(file_path)).await?;

let request = BatchRequest::new(uploaded_file.id.unwrap(), "/v1/responses".to_string());
let batch = batch_api::batches_post(&config, request).await?;
```

## Models & health

```rust
use ai_stats_sdk::{Client, apis::analytics_api};

let client = Client::new("your-api-key", "https://api.ai-stats.phaseo.app/v1");
let models = client.get_models(None, None, None).await?;
let health = analytics_api::healthz_get(&client.config).await?;
```

## Error handling

```rust
use ai_stats_sdk::apis::completions_api;
use ai_stats_sdk::models::{ChatCompletionsRequest, ChatMessage, MessageContent};

let request = ChatCompletionsRequest::new(
    "invalid".to_string(),
    vec![]
);

match completions_api::create_chat_completion(&config, request).await {
    Ok(response) => println!("{:?}", response),
    Err(e) => println!("API Error: {:?}", e),
}
```
