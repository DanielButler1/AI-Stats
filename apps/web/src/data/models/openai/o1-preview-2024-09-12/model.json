{
  "model_id": "openai/o1-preview-2024-09-12",
  "organisation_id": "openai",
  "name": "o1 preview",
  "status": "Retired",
  "previous_model_id": null,
  "announced_date": null,
  "release_date": "2024-09-12T00:00:00",
  "deprecation_date": "2025-04-28T00:00:00",
  "retirement_date": "2025-07-28T00:00:00",
  "license": "Proprietary",
  "input_types": "text",
  "output_types": "text",
  "family_id": "openai/o1",
  "links": [],
  "details": [
    {
      "name": "input_context_length",
      "value": 128000
    },
    {
      "name": "output_context_length",
      "value": 32768
    }
  ],
  "benchmarks": [
    {
      "benchmark_id": "aidanbench",
      "score": 1938,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://aidanbench.com/",
      "rank": 7
    },
    {
      "benchmark_id": "aime-2024",
      "score": 0.42,
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/",
      "rank": 33
    },
    {
      "benchmark_id": "confabulations",
      "score": 13.04,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://github.com/lechmazur/confabulations",
      "rank": 9
    },
    {
      "benchmark_id": "gpqa-diamond",
      "score": 0.733,
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/",
      "rank": 35
    },
    {
      "benchmark_id": "lmarena-text",
      "score": 1381,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://lmarena.ai/leaderboard/text",
      "rank": 18
    },
    {
      "benchmark_id": "simplebench",
      "score": 0.417,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://simple-bench.com/index.html",
      "rank": 9
    }
  ]
}