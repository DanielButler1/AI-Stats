{
  "id": "gemini-2.5-pro-preview-06-05",
  "name": "Gemini 2.5 Pro Preview",
  "provider": "google",
  "status": "Available",
  "previous_model_id": "gemini-2.5-pro-preview-05-06",
  "description": "The latest generally available version of Google's Gemini 2.5 Pro Model. Gemini 2.5 Pro is Google's Flagship multimodal model, offering the strongest performance across any of Google's models with complete multimodaliality, and a 1m input context length.",
  "announced_date": "2025-06-05T00:00:00",
  "release_date": "2025-06-05T00:00:00",
  "deprecation_date": "2026-06-17T00:00:00",
  "input_context_length": 1048576,
  "output_context_length": 65536,
  "license": "Proprietary",
  "multimodal": true,
  "input_types": "text,image,video,audio",
  "output_types": "text",
  "web_access": true,
  "reasoning": true,
  "fine_tunable": false,
  "knowledge_cutoff": "2025-01-01T00:00:00",
  "api_reference_link": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-pro-preview-06-05",
  "playground_link": "https://aistudio.google.com/prompts/new_chat",
  "paper_link": "",
  "announcement_link": "Gemini 2.5 Pro: Access Googleâ€™s latest preview AI model",
  "repository_link": "",
  "weights_link": "",
  "parameter_count": "",
  "training_tokens": "",
  "benchmark_results": [
    {
      "benchmark_id": "lmarena-text",
      "score": 1470,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://lmarena.ai/leaderboard/text"
    },
    {
      "benchmark_id": "humanitys-last-exam",
      "score": "21.6%",
      "is_self_reported": true,
      "other_info": "No Tools",
      "source_link": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_2-5_procomp_benchmarks_cropped_light_3.gif"
    },
    {
      "benchmark_id": "simpleqa",
      "score": "54.0%",
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_2-5_procomp_benchmarks_cropped_light_3.gif"
    },
    {
      "benchmark_id": "swe-bench",
      "score": "59.6%",
      "is_self_reported": true,
      "other_info": "Single Attempt",
      "source_link": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_2-5_procomp_benchmarks_cropped_light_3.gif"
    },
    {
      "benchmark_id": "simplebench",
      "score": "62.4%",
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://simple-bench.com/index.html"
    },
    {
      "benchmark_id": "swe-bench",
      "score": "67.2%",
      "is_self_reported": true,
      "other_info": "Multiple Attempts",
      "source_link": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_2-5_procomp_benchmarks_cropped_light_3.gif"
    },
    {
      "benchmark_id": "mmmu",
      "score": "82.0%",
      "is_self_reported": true,
      "other_info": "Single Attempt",
      "source_link": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_2-5_procomp_benchmarks_cropped_light_3.gif"
    },
    {
      "benchmark_id": "aider-polyglot",
      "score": "82.2%",
      "is_self_reported": false,
      "other_info": "Diff-Fenced",
      "source_link": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_2-5_procomp_benchmarks_cropped_light_3.gif"
    },
    {
      "benchmark_id": "gpqa-diamond",
      "score": "86.4%",
      "is_self_reported": true,
      "other_info": "Single Attempt",
      "source_link": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_2-5_procomp_benchmarks_cropped_light_3.gif"
    },
    {
      "benchmark_id": "aime-2025",
      "score": "88.0%",
      "is_self_reported": true,
      "other_info": "Single Attempt",
      "source_link": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_2-5_procomp_benchmarks_cropped_light_3.gif"
    },
    {
      "benchmark_id": "mmlu",
      "score": "89.2%",
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_2-5_procomp_benchmarks_cropped_light_3.gif"
    },
    {
      "benchmark_id": "lmarena-text",
      "score": 1470,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://lmarena.ai/leaderboard/text"
    },
    {
      "benchmark_id": "eqbench",
      "score": 1476.6,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://eqbench.com/"
    },
    {
      "benchmark_id": "confabulations",
      "score": 12.38,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://github.com/lechmazur/confabulations"
    },
    {
      "benchmark_id": "thematic-generalisation",
      "score": 1.79,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://github.com/lechmazur/generalization"
    },
    {
      "benchmark_id": "nyt-connections",
      "score": "58.7%",
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://github.com/lechmazur/nyt-connections"
    },
    {
      "benchmark_id": "elimination-game",
      "score": 4.036,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://github.com/lechmazur/elimination_game"
    },
    {
      "benchmark_id": "lmarena-webdev",
      "score": 1433.16,
      "is_self_reported": false,
      "other_info": "16th June 2025",
      "source_link": "https://web.lmarena.ai/leaderboard"
    },
    {
      "benchmark_id": "arc-agi-1",
      "score": "16.0%",
      "is_self_reported": false,
      "other_info": "1k Thinking",
      "source_link": "https://arcprize.org/leaderboard"
    },
    {
      "benchmark_id": "arc-agi-1",
      "score": "29.5%",
      "is_self_reported": false,
      "other_info": "8k Thinking",
      "source_link": "https://arcprize.org/leaderboard"
    },
    {
      "benchmark_id": "arc-agi-1",
      "score": "41.0%",
      "is_self_reported": false,
      "other_info": "16k Thinking",
      "source_link": "https://arcprize.org/leaderboard"
    },
    {
      "benchmark_id": "arc-agi-1",
      "score": "37.0%",
      "is_self_reported": false,
      "other_info": "32k Thinking",
      "source_link": "https://arcprize.org/leaderboard"
    },
    {
      "benchmark_id": "arc-agi-2",
      "score": "0.0%",
      "is_self_reported": false,
      "other_info": "1k Thinking",
      "source_link": "https://arcprize.org/leaderboard"
    },
    {
      "benchmark_id": "arc-agi-2",
      "score": "2.9%",
      "is_self_reported": false,
      "other_info": "8k Thinking",
      "source_link": "https://arcprize.org/leaderboard"
    },
    {
      "benchmark_id": "arc-agi-2",
      "score": "4.0%",
      "is_self_reported": false,
      "other_info": "16k Thinking",
      "source_link": "https://arcprize.org/leaderboard"
    },
    {
      "benchmark_id": "arc-agi-2",
      "score": "4.9%",
      "is_self_reported": false,
      "other_info": "32k Thinking",
      "source_link": "https://arcprize.org/leaderboard"
    },
    {
      "benchmark_id": "ai2-sciarena",
      "score": 1063,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://sciarena.allen.ai/"
    }
  ],
  "prices": [
    {
      "api_provider": "google-ai-studio",
      "input_token_price": "0.00000125",
      "cached_input_token_price": "0.00000031",
      "output_token_price": "0.00001",
      "throughput": "",
      "latency": "",
      "source_link": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro",
      "other_info": "Prices for input/output <200k tokens. Rises to $2.50 and $15 per 1m tokens >200k tokens. Cached Price rises to $0.625 per 1m tokens when prompts >200k tokens."
    },
    {
      "api_provider": "google-vertex",
      "input_token_price": "0.00000125",
      "cached_input_token_price": "0.00000031",
      "output_token_price": "0.00001",
      "throughput": "",
      "latency": "",
      "source_link": null,
      "other_info": "Prices for input/output <200k tokens. Rises to $2.50 and $15 per 1m tokens >200k tokens. Cached Price rises to $0.625 per 1m tokens when prompts >200k tokens."
    }
  ]
}