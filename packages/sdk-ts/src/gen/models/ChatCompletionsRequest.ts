/* tslint:disable */
/* eslint-disable */
/**
 * AI Stats Gateway API
 * A gateway API for accessing various AI models with OpenAI-compatible endpoints.
 *
 * The version of the OpenAPI document: 1.0.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { mapValues } from '../runtime';
import type { ChatCompletionsRequestToolChoice } from './ChatCompletionsRequestToolChoice';
import {
    ChatCompletionsRequestToolChoiceFromJSON,
    ChatCompletionsRequestToolChoiceFromJSONTyped,
    ChatCompletionsRequestToolChoiceToJSON,
    ChatCompletionsRequestToolChoiceToJSONTyped,
} from './ChatCompletionsRequestToolChoice';
import type { ChatCompletionsRequestResponseFormat } from './ChatCompletionsRequestResponseFormat';
import {
    ChatCompletionsRequestResponseFormatFromJSON,
    ChatCompletionsRequestResponseFormatFromJSONTyped,
    ChatCompletionsRequestResponseFormatToJSON,
    ChatCompletionsRequestResponseFormatToJSONTyped,
} from './ChatCompletionsRequestResponseFormat';
import type { ChatMessage } from './ChatMessage';
import {
    ChatMessageFromJSON,
    ChatMessageFromJSONTyped,
    ChatMessageToJSON,
    ChatMessageToJSONTyped,
} from './ChatMessage';
import type { ChatCompletionsRequestToolsInner } from './ChatCompletionsRequestToolsInner';
import {
    ChatCompletionsRequestToolsInnerFromJSON,
    ChatCompletionsRequestToolsInnerFromJSONTyped,
    ChatCompletionsRequestToolsInnerToJSON,
    ChatCompletionsRequestToolsInnerToJSONTyped,
} from './ChatCompletionsRequestToolsInner';
import type { ReasoningConfig } from './ReasoningConfig';
import {
    ReasoningConfigFromJSON,
    ReasoningConfigFromJSONTyped,
    ReasoningConfigToJSON,
    ReasoningConfigToJSONTyped,
} from './ReasoningConfig';

/**
 * 
 * @export
 * @interface ChatCompletionsRequest
 */
export interface ChatCompletionsRequest {
    /**
     * 
     * @type {string}
     * @memberof ChatCompletionsRequest
     */
    model: string;
    /**
     * 
     * @type {string}
     * @memberof ChatCompletionsRequest
     */
    system?: string;
    /**
     * 
     * @type {Array<ChatMessage>}
     * @memberof ChatCompletionsRequest
     */
    messages: Array<ChatMessage>;
    /**
     * 
     * @type {ReasoningConfig}
     * @memberof ChatCompletionsRequest
     */
    reasoning?: ReasoningConfig;
    /**
     * 
     * @type {number}
     * @memberof ChatCompletionsRequest
     */
    frequency_penalty?: number;
    /**
     * 
     * @type {{ [key: string]: number; }}
     * @memberof ChatCompletionsRequest
     */
    logit_bias?: { [key: string]: number; };
    /**
     * 
     * @type {number}
     * @memberof ChatCompletionsRequest
     */
    max_output_tokens?: number;
    /**
     * 
     * @type {boolean}
     * @memberof ChatCompletionsRequest
     */
    meta?: boolean;
    /**
     * 
     * @type {number}
     * @memberof ChatCompletionsRequest
     */
    presence_penalty?: number;
    /**
     * 
     * @type {number}
     * @memberof ChatCompletionsRequest
     */
    seed?: number;
    /**
     * 
     * @type {boolean}
     * @memberof ChatCompletionsRequest
     */
    stream?: boolean;
    /**
     * 
     * @type {number}
     * @memberof ChatCompletionsRequest
     */
    temperature?: number;
    /**
     * 
     * @type {Array<ChatCompletionsRequestToolsInner>}
     * @memberof ChatCompletionsRequest
     */
    tools?: Array<ChatCompletionsRequestToolsInner>;
    /**
     * 
     * @type {number}
     * @memberof ChatCompletionsRequest
     */
    max_tool_calls?: number;
    /**
     * 
     * @type {boolean}
     * @memberof ChatCompletionsRequest
     */
    parallel_tool_calls?: boolean;
    /**
     * 
     * @type {ChatCompletionsRequestToolChoice}
     * @memberof ChatCompletionsRequest
     */
    tool_choice?: ChatCompletionsRequestToolChoice;
    /**
     * 
     * @type {number}
     * @memberof ChatCompletionsRequest
     */
    top_k?: number;
    /**
     * 
     * @type {boolean}
     * @memberof ChatCompletionsRequest
     */
    logprobs?: boolean;
    /**
     * 
     * @type {number}
     * @memberof ChatCompletionsRequest
     */
    top_logprobs?: number;
    /**
     * 
     * @type {number}
     * @memberof ChatCompletionsRequest
     */
    top_p?: number;
    /**
     * 
     * @type {ChatCompletionsRequestResponseFormat}
     * @memberof ChatCompletionsRequest
     */
    response_format?: ChatCompletionsRequestResponseFormat;
    /**
     * 
     * @type {boolean}
     * @memberof ChatCompletionsRequest
     */
    usage?: boolean;
    /**
     * 
     * @type {string}
     * @memberof ChatCompletionsRequest
     */
    user_id?: string;
    /**
     * 
     * @type {string}
     * @memberof ChatCompletionsRequest
     */
    service_tier?: ChatCompletionsRequestServiceTierEnum;
}

/**
* @export
* @enum {string}
*/
export enum ChatCompletionsRequestServiceTierEnum {
    flex = 'flex',
    standard = 'standard',
    priority = 'priority'
}


/**
 * Check if a given object implements the ChatCompletionsRequest interface.
 */
export function instanceOfChatCompletionsRequest(value: object): value is ChatCompletionsRequest {
    if (!('model' in value) || value['model'] === undefined) return false;
    if (!('messages' in value) || value['messages'] === undefined) return false;
    return true;
}

export function ChatCompletionsRequestFromJSON(json: any): ChatCompletionsRequest {
    return ChatCompletionsRequestFromJSONTyped(json, false);
}

export function ChatCompletionsRequestFromJSONTyped(json: any, ignoreDiscriminator: boolean): ChatCompletionsRequest {
    if (json == null) {
        return json;
    }
    return {
        
        'model': json['model'],
        'system': json['system'] == null ? undefined : json['system'],
        'messages': ((json['messages'] as Array<any>).map(ChatMessageFromJSON)),
        'reasoning': json['reasoning'] == null ? undefined : ReasoningConfigFromJSON(json['reasoning']),
        'frequency_penalty': json['frequency_penalty'] == null ? undefined : json['frequency_penalty'],
        'logit_bias': json['logit_bias'] == null ? undefined : json['logit_bias'],
        'max_output_tokens': json['max_output_tokens'] == null ? undefined : json['max_output_tokens'],
        'meta': json['meta'] == null ? undefined : json['meta'],
        'presence_penalty': json['presence_penalty'] == null ? undefined : json['presence_penalty'],
        'seed': json['seed'] == null ? undefined : json['seed'],
        'stream': json['stream'] == null ? undefined : json['stream'],
        'temperature': json['temperature'] == null ? undefined : json['temperature'],
        'tools': json['tools'] == null ? undefined : ((json['tools'] as Array<any>).map(ChatCompletionsRequestToolsInnerFromJSON)),
        'max_tool_calls': json['max_tool_calls'] == null ? undefined : json['max_tool_calls'],
        'parallel_tool_calls': json['parallel_tool_calls'] == null ? undefined : json['parallel_tool_calls'],
        'tool_choice': json['tool_choice'] == null ? undefined : ChatCompletionsRequestToolChoiceFromJSON(json['tool_choice']),
        'top_k': json['top_k'] == null ? undefined : json['top_k'],
        'logprobs': json['logprobs'] == null ? undefined : json['logprobs'],
        'top_logprobs': json['top_logprobs'] == null ? undefined : json['top_logprobs'],
        'top_p': json['top_p'] == null ? undefined : json['top_p'],
        'response_format': json['response_format'] == null ? undefined : ChatCompletionsRequestResponseFormatFromJSON(json['response_format']),
        'usage': json['usage'] == null ? undefined : json['usage'],
        'user_id': json['user_id'] == null ? undefined : json['user_id'],
        'service_tier': json['service_tier'] == null ? undefined : json['service_tier'],
    };
}

export function ChatCompletionsRequestToJSON(json: any): ChatCompletionsRequest {
    return ChatCompletionsRequestToJSONTyped(json, false);
}

export function ChatCompletionsRequestToJSONTyped(value?: ChatCompletionsRequest | null, ignoreDiscriminator: boolean = false): any {
    if (value == null) {
        return value;
    }

    return {
        
        'model': value['model'],
        'system': value['system'],
        'messages': ((value['messages'] as Array<any>).map(ChatMessageToJSON)),
        'reasoning': ReasoningConfigToJSON(value['reasoning']),
        'frequency_penalty': value['frequency_penalty'],
        'logit_bias': value['logit_bias'],
        'max_output_tokens': value['max_output_tokens'],
        'meta': value['meta'],
        'presence_penalty': value['presence_penalty'],
        'seed': value['seed'],
        'stream': value['stream'],
        'temperature': value['temperature'],
        'tools': value['tools'] == null ? undefined : ((value['tools'] as Array<any>).map(ChatCompletionsRequestToolsInnerToJSON)),
        'max_tool_calls': value['max_tool_calls'],
        'parallel_tool_calls': value['parallel_tool_calls'],
        'tool_choice': ChatCompletionsRequestToolChoiceToJSON(value['tool_choice']),
        'top_k': value['top_k'],
        'logprobs': value['logprobs'],
        'top_logprobs': value['top_logprobs'],
        'top_p': value['top_p'],
        'response_format': ChatCompletionsRequestResponseFormatToJSON(value['response_format']),
        'usage': value['usage'],
        'user_id': value['user_id'],
        'service_tier': value['service_tier'],
    };
}

