/* tslint:disable */
/* eslint-disable */
/**
 * AI Stats Gateway API
 * A gateway API for accessing various AI models with OpenAI-compatible endpoints.
 *
 * The version of the OpenAPI document: 1.0.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { mapValues } from '../runtime';
import type { ChatCompletionsRequestToolChoice } from './ChatCompletionsRequestToolChoice';
import {
    ChatCompletionsRequestToolChoiceFromJSON,
    ChatCompletionsRequestToolChoiceFromJSONTyped,
    ChatCompletionsRequestToolChoiceToJSON,
    ChatCompletionsRequestToolChoiceToJSONTyped,
} from './ChatCompletionsRequestToolChoice';
import type { ResponsesRequestReasoning } from './ResponsesRequestReasoning';
import {
    ResponsesRequestReasoningFromJSON,
    ResponsesRequestReasoningFromJSONTyped,
    ResponsesRequestReasoningToJSON,
    ResponsesRequestReasoningToJSONTyped,
} from './ResponsesRequestReasoning';
import type { ResponsesRequestPrompt } from './ResponsesRequestPrompt';
import {
    ResponsesRequestPromptFromJSON,
    ResponsesRequestPromptFromJSONTyped,
    ResponsesRequestPromptToJSON,
    ResponsesRequestPromptToJSONTyped,
} from './ResponsesRequestPrompt';

/**
 * 
 * @export
 * @interface ResponsesRequest
 */
export interface ResponsesRequest {
    /**
     * 
     * @type {string}
     * @memberof ResponsesRequest
     */
    model: string;
    /**
     * 
     * @type {object}
     * @memberof ResponsesRequest
     */
    input?: object;
    /**
     * 
     * @type {Array<object>}
     * @memberof ResponsesRequest
     */
    input_items?: Array<object>;
    /**
     * 
     * @type {ChatCompletionsRequestToolChoice}
     * @memberof ResponsesRequest
     */
    conversation?: ChatCompletionsRequestToolChoice;
    /**
     * 
     * @type {Array<string>}
     * @memberof ResponsesRequest
     */
    include?: Array<string>;
    /**
     * 
     * @type {string}
     * @memberof ResponsesRequest
     */
    instructions?: string;
    /**
     * 
     * @type {number}
     * @memberof ResponsesRequest
     */
    max_output_tokens?: number;
    /**
     * 
     * @type {number}
     * @memberof ResponsesRequest
     */
    max_tool_calls?: number;
    /**
     * 
     * @type {{ [key: string]: string; }}
     * @memberof ResponsesRequest
     */
    metadata?: { [key: string]: string; };
    /**
     * 
     * @type {boolean}
     * @memberof ResponsesRequest
     */
    parallel_tool_calls?: boolean;
    /**
     * 
     * @type {string}
     * @memberof ResponsesRequest
     */
    previous_response_id?: string;
    /**
     * 
     * @type {ResponsesRequestPrompt}
     * @memberof ResponsesRequest
     */
    prompt?: ResponsesRequestPrompt;
    /**
     * 
     * @type {string}
     * @memberof ResponsesRequest
     */
    prompt_cache_key?: string;
    /**
     * 
     * @type {string}
     * @memberof ResponsesRequest
     */
    prompt_cache_retention?: string;
    /**
     * 
     * @type {ResponsesRequestReasoning}
     * @memberof ResponsesRequest
     */
    reasoning?: ResponsesRequestReasoning;
    /**
     * 
     * @type {string}
     * @memberof ResponsesRequest
     */
    safety_identifier?: string;
    /**
     * 
     * @type {string}
     * @memberof ResponsesRequest
     */
    service_tier?: string;
    /**
     * 
     * @type {boolean}
     * @memberof ResponsesRequest
     */
    store?: boolean;
    /**
     * 
     * @type {boolean}
     * @memberof ResponsesRequest
     */
    stream?: boolean;
    /**
     * 
     * @type {object}
     * @memberof ResponsesRequest
     */
    stream_options?: object;
    /**
     * 
     * @type {number}
     * @memberof ResponsesRequest
     */
    temperature?: number;
    /**
     * 
     * @type {object}
     * @memberof ResponsesRequest
     */
    text?: object;
    /**
     * 
     * @type {ChatCompletionsRequestToolChoice}
     * @memberof ResponsesRequest
     */
    tool_choice?: ChatCompletionsRequestToolChoice;
    /**
     * 
     * @type {Array<object>}
     * @memberof ResponsesRequest
     */
    tools?: Array<object>;
    /**
     * 
     * @type {number}
     * @memberof ResponsesRequest
     */
    top_logprobs?: number;
    /**
     * 
     * @type {number}
     * @memberof ResponsesRequest
     */
    top_p?: number;
    /**
     * 
     * @type {string}
     * @memberof ResponsesRequest
     */
    truncation?: string;
    /**
     * 
     * @type {boolean}
     * @memberof ResponsesRequest
     */
    background?: boolean;
    /**
     * 
     * @type {string}
     * @memberof ResponsesRequest
     */
    user?: string;
    /**
     * 
     * @type {boolean}
     * @memberof ResponsesRequest
     */
    usage?: boolean;
    /**
     * 
     * @type {boolean}
     * @memberof ResponsesRequest
     */
    meta?: boolean;
}

/**
 * Check if a given object implements the ResponsesRequest interface.
 */
export function instanceOfResponsesRequest(value: object): value is ResponsesRequest {
    if (!('model' in value) || value['model'] === undefined) return false;
    return true;
}

export function ResponsesRequestFromJSON(json: any): ResponsesRequest {
    return ResponsesRequestFromJSONTyped(json, false);
}

export function ResponsesRequestFromJSONTyped(json: any, ignoreDiscriminator: boolean): ResponsesRequest {
    if (json == null) {
        return json;
    }
    return {
        
        'model': json['model'],
        'input': json['input'] == null ? undefined : json['input'],
        'input_items': json['input_items'] == null ? undefined : json['input_items'],
        'conversation': json['conversation'] == null ? undefined : ChatCompletionsRequestToolChoiceFromJSON(json['conversation']),
        'include': json['include'] == null ? undefined : json['include'],
        'instructions': json['instructions'] == null ? undefined : json['instructions'],
        'max_output_tokens': json['max_output_tokens'] == null ? undefined : json['max_output_tokens'],
        'max_tool_calls': json['max_tool_calls'] == null ? undefined : json['max_tool_calls'],
        'metadata': json['metadata'] == null ? undefined : json['metadata'],
        'parallel_tool_calls': json['parallel_tool_calls'] == null ? undefined : json['parallel_tool_calls'],
        'previous_response_id': json['previous_response_id'] == null ? undefined : json['previous_response_id'],
        'prompt': json['prompt'] == null ? undefined : ResponsesRequestPromptFromJSON(json['prompt']),
        'prompt_cache_key': json['prompt_cache_key'] == null ? undefined : json['prompt_cache_key'],
        'prompt_cache_retention': json['prompt_cache_retention'] == null ? undefined : json['prompt_cache_retention'],
        'reasoning': json['reasoning'] == null ? undefined : ResponsesRequestReasoningFromJSON(json['reasoning']),
        'safety_identifier': json['safety_identifier'] == null ? undefined : json['safety_identifier'],
        'service_tier': json['service_tier'] == null ? undefined : json['service_tier'],
        'store': json['store'] == null ? undefined : json['store'],
        'stream': json['stream'] == null ? undefined : json['stream'],
        'stream_options': json['stream_options'] == null ? undefined : json['stream_options'],
        'temperature': json['temperature'] == null ? undefined : json['temperature'],
        'text': json['text'] == null ? undefined : json['text'],
        'tool_choice': json['tool_choice'] == null ? undefined : ChatCompletionsRequestToolChoiceFromJSON(json['tool_choice']),
        'tools': json['tools'] == null ? undefined : json['tools'],
        'top_logprobs': json['top_logprobs'] == null ? undefined : json['top_logprobs'],
        'top_p': json['top_p'] == null ? undefined : json['top_p'],
        'truncation': json['truncation'] == null ? undefined : json['truncation'],
        'background': json['background'] == null ? undefined : json['background'],
        'user': json['user'] == null ? undefined : json['user'],
        'usage': json['usage'] == null ? undefined : json['usage'],
        'meta': json['meta'] == null ? undefined : json['meta'],
    };
}

export function ResponsesRequestToJSON(json: any): ResponsesRequest {
    return ResponsesRequestToJSONTyped(json, false);
}

export function ResponsesRequestToJSONTyped(value?: ResponsesRequest | null, ignoreDiscriminator: boolean = false): any {
    if (value == null) {
        return value;
    }

    return {
        
        'model': value['model'],
        'input': value['input'],
        'input_items': value['input_items'],
        'conversation': ChatCompletionsRequestToolChoiceToJSON(value['conversation']),
        'include': value['include'],
        'instructions': value['instructions'],
        'max_output_tokens': value['max_output_tokens'],
        'max_tool_calls': value['max_tool_calls'],
        'metadata': value['metadata'],
        'parallel_tool_calls': value['parallel_tool_calls'],
        'previous_response_id': value['previous_response_id'],
        'prompt': ResponsesRequestPromptToJSON(value['prompt']),
        'prompt_cache_key': value['prompt_cache_key'],
        'prompt_cache_retention': value['prompt_cache_retention'],
        'reasoning': ResponsesRequestReasoningToJSON(value['reasoning']),
        'safety_identifier': value['safety_identifier'],
        'service_tier': value['service_tier'],
        'store': value['store'],
        'stream': value['stream'],
        'stream_options': value['stream_options'],
        'temperature': value['temperature'],
        'text': value['text'],
        'tool_choice': ChatCompletionsRequestToolChoiceToJSON(value['tool_choice']),
        'tools': value['tools'],
        'top_logprobs': value['top_logprobs'],
        'top_p': value['top_p'],
        'truncation': value['truncation'],
        'background': value['background'],
        'user': value['user'],
        'usage': value['usage'],
        'meta': value['meta'],
    };
}

