/**
 * AI Stats Gateway API
 * Programmatic access to the AI Stats AI Gateway. All endpoints forward requests to the best available provider for the specified model, and return normalised responses with clear structured metadata.
 *
 * The version of the OpenAPI document: 0.1.0
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.17.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */



#include "ai_stats_sdk_cpp/model/AIStatsGatewayUsage.h"

namespace org {
namespace openapitools {
namespace client {
namespace model {

AIStatsGatewayUsage::AIStatsGatewayUsage()
{
    m_Total_tokens = 0;
    m_Total_tokensIsSet = false;
    m_Input_text_tokens = 0;
    m_Input_text_tokensIsSet = false;
    m_Output_text_tokens = 0;
    m_Output_text_tokensIsSet = false;
    m_Reasoning_tokens = 0;
    m_Reasoning_tokensIsSet = false;
    m_Cached_read_text_tokens = 0;
    m_Cached_read_text_tokensIsSet = false;
}

AIStatsGatewayUsage::~AIStatsGatewayUsage()
{
}

void AIStatsGatewayUsage::validate()
{
    // TODO: implement validation
}

web::json::value AIStatsGatewayUsage::toJson() const
{
    web::json::value val = web::json::value::object();
    if(m_Total_tokensIsSet)
    {   
        
        val[utility::conversions::to_string_t(_XPLATSTR("total_tokens"))] = ModelBase::toJson(m_Total_tokens);
    }
    if(m_Input_text_tokensIsSet)
    {   
        
        val[utility::conversions::to_string_t(_XPLATSTR("input_text_tokens"))] = ModelBase::toJson(m_Input_text_tokens);
    }
    if(m_Output_text_tokensIsSet)
    {   
        
        val[utility::conversions::to_string_t(_XPLATSTR("output_text_tokens"))] = ModelBase::toJson(m_Output_text_tokens);
    }
    if(m_Reasoning_tokensIsSet)
    {   
        
        val[utility::conversions::to_string_t(_XPLATSTR("reasoning_tokens"))] = ModelBase::toJson(m_Reasoning_tokens);
    }
    if(m_Cached_read_text_tokensIsSet)
    {   
        
        val[utility::conversions::to_string_t(_XPLATSTR("cached_read_text_tokens"))] = ModelBase::toJson(m_Cached_read_text_tokens);
    }

    return val;
}

bool AIStatsGatewayUsage::fromJson(const web::json::value& val)
{
    bool ok = true;
    if(val.has_field(utility::conversions::to_string_t(_XPLATSTR("total_tokens"))))
    {
        const web::json::value& fieldValue = val.at(utility::conversions::to_string_t(_XPLATSTR("total_tokens")));
        if(!fieldValue.is_null())
        {
            int32_t refVal_setTotalTokens;
            ok &= ModelBase::fromJson(fieldValue, refVal_setTotalTokens);
            setTotalTokens(refVal_setTotalTokens);
            
        }
    }
    if(val.has_field(utility::conversions::to_string_t(_XPLATSTR("input_text_tokens"))))
    {
        const web::json::value& fieldValue = val.at(utility::conversions::to_string_t(_XPLATSTR("input_text_tokens")));
        if(!fieldValue.is_null())
        {
            int32_t refVal_setInputTextTokens;
            ok &= ModelBase::fromJson(fieldValue, refVal_setInputTextTokens);
            setInputTextTokens(refVal_setInputTextTokens);
            
        }
    }
    if(val.has_field(utility::conversions::to_string_t(_XPLATSTR("output_text_tokens"))))
    {
        const web::json::value& fieldValue = val.at(utility::conversions::to_string_t(_XPLATSTR("output_text_tokens")));
        if(!fieldValue.is_null())
        {
            int32_t refVal_setOutputTextTokens;
            ok &= ModelBase::fromJson(fieldValue, refVal_setOutputTextTokens);
            setOutputTextTokens(refVal_setOutputTextTokens);
            
        }
    }
    if(val.has_field(utility::conversions::to_string_t(_XPLATSTR("reasoning_tokens"))))
    {
        const web::json::value& fieldValue = val.at(utility::conversions::to_string_t(_XPLATSTR("reasoning_tokens")));
        if(!fieldValue.is_null())
        {
            int32_t refVal_setReasoningTokens;
            ok &= ModelBase::fromJson(fieldValue, refVal_setReasoningTokens);
            setReasoningTokens(refVal_setReasoningTokens);
            
        }
    }
    if(val.has_field(utility::conversions::to_string_t(_XPLATSTR("cached_read_text_tokens"))))
    {
        const web::json::value& fieldValue = val.at(utility::conversions::to_string_t(_XPLATSTR("cached_read_text_tokens")));
        if(!fieldValue.is_null())
        {
            int32_t refVal_setCachedReadTextTokens;
            ok &= ModelBase::fromJson(fieldValue, refVal_setCachedReadTextTokens);
            setCachedReadTextTokens(refVal_setCachedReadTextTokens);
            
        }
    }
    return ok;
}

void AIStatsGatewayUsage::toMultipart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& prefix) const
{
    utility::string_t namePrefix = prefix;
    if(namePrefix.size() > 0 && namePrefix.substr(namePrefix.size() - 1) != utility::conversions::to_string_t(_XPLATSTR(".")))
    {
        namePrefix += utility::conversions::to_string_t(_XPLATSTR("."));
    }
    if(m_Total_tokensIsSet)
    {
        multipart->add(ModelBase::toHttpContent(namePrefix + utility::conversions::to_string_t(_XPLATSTR("total_tokens")), m_Total_tokens));
    }
    if(m_Input_text_tokensIsSet)
    {
        multipart->add(ModelBase::toHttpContent(namePrefix + utility::conversions::to_string_t(_XPLATSTR("input_text_tokens")), m_Input_text_tokens));
    }
    if(m_Output_text_tokensIsSet)
    {
        multipart->add(ModelBase::toHttpContent(namePrefix + utility::conversions::to_string_t(_XPLATSTR("output_text_tokens")), m_Output_text_tokens));
    }
    if(m_Reasoning_tokensIsSet)
    {
        multipart->add(ModelBase::toHttpContent(namePrefix + utility::conversions::to_string_t(_XPLATSTR("reasoning_tokens")), m_Reasoning_tokens));
    }
    if(m_Cached_read_text_tokensIsSet)
    {
        multipart->add(ModelBase::toHttpContent(namePrefix + utility::conversions::to_string_t(_XPLATSTR("cached_read_text_tokens")), m_Cached_read_text_tokens));
    }
}

bool AIStatsGatewayUsage::fromMultiPart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& prefix)
{
    bool ok = true;
    utility::string_t namePrefix = prefix;
    if(namePrefix.size() > 0 && namePrefix.substr(namePrefix.size() - 1) != utility::conversions::to_string_t(_XPLATSTR(".")))
    {
        namePrefix += utility::conversions::to_string_t(_XPLATSTR("."));
    }

    if(multipart->hasContent(utility::conversions::to_string_t(_XPLATSTR("total_tokens"))))
    {
        int32_t refVal_setTotalTokens;
        ok &= ModelBase::fromHttpContent(multipart->getContent(utility::conversions::to_string_t(_XPLATSTR("total_tokens"))), refVal_setTotalTokens );
        setTotalTokens(refVal_setTotalTokens);
    }
    if(multipart->hasContent(utility::conversions::to_string_t(_XPLATSTR("input_text_tokens"))))
    {
        int32_t refVal_setInputTextTokens;
        ok &= ModelBase::fromHttpContent(multipart->getContent(utility::conversions::to_string_t(_XPLATSTR("input_text_tokens"))), refVal_setInputTextTokens );
        setInputTextTokens(refVal_setInputTextTokens);
    }
    if(multipart->hasContent(utility::conversions::to_string_t(_XPLATSTR("output_text_tokens"))))
    {
        int32_t refVal_setOutputTextTokens;
        ok &= ModelBase::fromHttpContent(multipart->getContent(utility::conversions::to_string_t(_XPLATSTR("output_text_tokens"))), refVal_setOutputTextTokens );
        setOutputTextTokens(refVal_setOutputTextTokens);
    }
    if(multipart->hasContent(utility::conversions::to_string_t(_XPLATSTR("reasoning_tokens"))))
    {
        int32_t refVal_setReasoningTokens;
        ok &= ModelBase::fromHttpContent(multipart->getContent(utility::conversions::to_string_t(_XPLATSTR("reasoning_tokens"))), refVal_setReasoningTokens );
        setReasoningTokens(refVal_setReasoningTokens);
    }
    if(multipart->hasContent(utility::conversions::to_string_t(_XPLATSTR("cached_read_text_tokens"))))
    {
        int32_t refVal_setCachedReadTextTokens;
        ok &= ModelBase::fromHttpContent(multipart->getContent(utility::conversions::to_string_t(_XPLATSTR("cached_read_text_tokens"))), refVal_setCachedReadTextTokens );
        setCachedReadTextTokens(refVal_setCachedReadTextTokens);
    }
    return ok;
}


int32_t AIStatsGatewayUsage::getTotalTokens() const
{
    return m_Total_tokens;
}

void AIStatsGatewayUsage::setTotalTokens(int32_t value)
{
    m_Total_tokens = value;
    m_Total_tokensIsSet = true;
}

bool AIStatsGatewayUsage::totalTokensIsSet() const
{
    return m_Total_tokensIsSet;
}

void AIStatsGatewayUsage::unsetTotal_tokens()
{
    m_Total_tokensIsSet = false;
}
int32_t AIStatsGatewayUsage::getInputTextTokens() const
{
    return m_Input_text_tokens;
}

void AIStatsGatewayUsage::setInputTextTokens(int32_t value)
{
    m_Input_text_tokens = value;
    m_Input_text_tokensIsSet = true;
}

bool AIStatsGatewayUsage::inputTextTokensIsSet() const
{
    return m_Input_text_tokensIsSet;
}

void AIStatsGatewayUsage::unsetInput_text_tokens()
{
    m_Input_text_tokensIsSet = false;
}
int32_t AIStatsGatewayUsage::getOutputTextTokens() const
{
    return m_Output_text_tokens;
}

void AIStatsGatewayUsage::setOutputTextTokens(int32_t value)
{
    m_Output_text_tokens = value;
    m_Output_text_tokensIsSet = true;
}

bool AIStatsGatewayUsage::outputTextTokensIsSet() const
{
    return m_Output_text_tokensIsSet;
}

void AIStatsGatewayUsage::unsetOutput_text_tokens()
{
    m_Output_text_tokensIsSet = false;
}
int32_t AIStatsGatewayUsage::getReasoningTokens() const
{
    return m_Reasoning_tokens;
}

void AIStatsGatewayUsage::setReasoningTokens(int32_t value)
{
    m_Reasoning_tokens = value;
    m_Reasoning_tokensIsSet = true;
}

bool AIStatsGatewayUsage::reasoningTokensIsSet() const
{
    return m_Reasoning_tokensIsSet;
}

void AIStatsGatewayUsage::unsetReasoning_tokens()
{
    m_Reasoning_tokensIsSet = false;
}
int32_t AIStatsGatewayUsage::getCachedReadTextTokens() const
{
    return m_Cached_read_text_tokens;
}

void AIStatsGatewayUsage::setCachedReadTextTokens(int32_t value)
{
    m_Cached_read_text_tokens = value;
    m_Cached_read_text_tokensIsSet = true;
}

bool AIStatsGatewayUsage::cachedReadTextTokensIsSet() const
{
    return m_Cached_read_text_tokensIsSet;
}

void AIStatsGatewayUsage::unsetCached_read_text_tokens()
{
    m_Cached_read_text_tokensIsSet = false;
}

}
}
}
}


