/**
 * AI Stats Gateway API
 * Programmatic access to the AI Stats AI Gateway. All endpoints forward requests to the best available provider for the specified model, and return normalised responses with clear structured metadata.
 *
 * The version of the OpenAPI document: 0.1.0
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.17.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * AIStatsGatewayChatChoice.h
 *
 * 
 */

#ifndef ORG_OPENAPITOOLS_CLIENT_MODEL_AIStatsGatewayChatChoice_H_
#define ORG_OPENAPITOOLS_CLIENT_MODEL_AIStatsGatewayChatChoice_H_

#include <stdexcept>

#include "ai_stats_sdk_cpp/ModelBase.h"

#include "ai_stats_sdk_cpp/model/AIStatsAIStatsGatewayChatChoice_message.h"
#include <cpprest/details/basic_types.h>

namespace org {
namespace openapitools {
namespace client {
namespace model {

class AIStatsGatewayChatChoice_message;


class  AIStatsGatewayChatChoice
    : public ModelBase
{
public:
    AIStatsGatewayChatChoice();
    virtual ~AIStatsGatewayChatChoice();

    /////////////////////////////////////////////
    /// ModelBase overrides

    void validate() override;

    web::json::value toJson() const override;
    bool fromJson(const web::json::value& json) override;

    void toMultipart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) const override;
    bool fromMultiPart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) override;


    /////////////////////////////////////////////
    /// AIStatsGatewayChatChoice members

    enum class Finish_reasonEnum
    {
        STOP,
        LENGTH,
        TOOL_CALLS,
        CONTENT_FILTER,
        ERROR,
    };
    /// <summary>
    /// Why the model stopped generating tokens.
    /// </summary>

    Finish_reasonEnum toFinish_reasonEnum(const utility::string_t& value) const;
    const utility::string_t fromFinish_reasonEnum(const Finish_reasonEnum value) const;


    int32_t getIndex() const;
    bool indexIsSet() const;
    void unsetIndex();
    void setIndex(int32_t value);

    std::shared_ptr<AIStatsGatewayChatChoice_message> getMessage() const;
    bool messageIsSet() const;
    void unsetMessage();
    void setMessage(const std::shared_ptr<AIStatsGatewayChatChoice_message>& value);

    /// <summary>
    /// Why the model stopped generating tokens.
    /// </summary>
    Finish_reasonEnum getFinishReason() const;
    bool finishReasonIsSet() const;
    void unsetFinish_reason();
    void setFinishReason(const Finish_reasonEnum value);

    /// <summary>
    /// True when the choice contains provider reasoning traces.
    /// </summary>
    bool isReasoning() const;
    bool reasoningIsSet() const;
    void unsetReasoning();
    void setReasoning(bool value);


protected:
    int32_t m_Index;
    bool m_IndexIsSet;

    std::shared_ptr<AIStatsGatewayChatChoice_message> m_Message;
    bool m_MessageIsSet;

    Finish_reasonEnum m_Finish_reason;
    bool m_Finish_reasonIsSet;

    bool m_Reasoning;
    bool m_ReasoningIsSet;

};


}
}
}
}

#endif /* ORG_OPENAPITOOLS_CLIENT_MODEL_AIStatsGatewayChatChoice_H_ */
