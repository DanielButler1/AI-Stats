/*
 * AI Stats Gateway API
 *
 * Programmatic access to the AI Stats AI Gateway. All endpoints forward requests to the best available provider for the specified model, and return normalised responses with clear structured metadata.
 *
 * The version of the OpenAPI document: 0.1.0
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct GatewayChatChoice {
    #[serde(rename = "index")]
    pub index: i32,
    #[serde(rename = "message")]
    pub message: models::GatewayChatChoiceMessage,
    /// Why the model stopped generating tokens.
    #[serde(rename = "finish_reason", deserialize_with = "Option::deserialize")]
    pub finish_reason: Option<FinishReason>,
    /// True when the choice contains provider reasoning traces.
    #[serde(rename = "reasoning", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub reasoning: Option<Option<bool>>,
}

impl GatewayChatChoice {
    pub fn new(index: i32, message: models::GatewayChatChoiceMessage, finish_reason: Option<FinishReason>) -> GatewayChatChoice {
        GatewayChatChoice {
            index,
            message,
            finish_reason,
            reasoning: None,
        }
    }
}
/// Why the model stopped generating tokens.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum FinishReason {
    #[serde(rename = "stop")]
    Stop,
    #[serde(rename = "length")]
    Length,
    #[serde(rename = "tool_calls")]
    ToolCalls,
    #[serde(rename = "content_filter")]
    ContentFilter,
    #[serde(rename = "error")]
    Error,
}

impl Default for FinishReason {
    fn default() -> FinishReason {
        Self::Stop
    }
}

